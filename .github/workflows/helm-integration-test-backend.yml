name: Helm Integration Test Reusable (backend)

on:
  workflow_call:
    inputs:
      component:
        required: true
        type: string
      target:
        required: true
        type: string

concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  helm-integration-test-latest-linux:
    if: inputs.target == 'latest'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    steps:
      # mono occupies port 8084 which conflicts with mgmt-backend
      - name: Stop mono service
        run: |
          sudo kill -9 `sudo lsof -t -i:8084`
          sudo lsof -i -P -n | grep LISTEN

      - name: Pre Free Disk Space (Ubuntu)
        run: |
          df --human-readable
          sudo apt clean
          rm --recursive --force "$AGENT_TOOLSDIRECTORY"

      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: false
          docker-images: true
          swap-storage: true

      - name: Start Minikube
        run: minikube start --cpus 4 --memory 12G

      - name: Checkout repo (core)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/core

      - name: Load .env file (core)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Launch Helm Instill Core (latest)
        run: |
          helm install core charts/core --namespace instill-ai --create-namespace \
            --set edition=k8s-ce:test \
            --set apiGateway.image.tag=latest \
            --set mgmtBackend.image.tag=latest \
            --set console.image.tag=latest \
            --set tags.observability=false \
            --set tags.prometheusStack=false

      - name: Wait for core pods up
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Port-forward of api-gateway
        run: |
          API_GATEWAY_POD_NAME=$(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o json | jq -r '.items[0].metadata.name')
          kubectl --namespace instill-ai port-forward ${API_GATEWAY_POD_NAME} ${API_GATEWAY_PORT}:${API_GATEWAY_PORT} > /dev/null 2>&1 &
          while ! nc -vz localhost ${API_GATEWAY_PORT} > /dev/null 2>&1; do sleep 1; done

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file (model)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Install k6
        run: |
          curl https://github.com/grafana/k6/releases/download/v${{ env.K6_VERSION }}/k6-v${{ env.K6_VERSION }}-linux-amd64.tar.gz -L | tar xvz --strip-components 1 && sudo cp k6 /usr/bin

      - name: Launch Helm Instill Model (latest)
        run: |
          helm install model charts/model --namespace instill-ai \
            --set itMode.enabled=true \
            --set edition=k8s-ce:test \
            --set modelBackend.image.tag=latest \
            --set controllerModel.image.tag=latest \
            --set rayService.image.tag=latest-cpu \
            --set rayService.headGroupSpec.resources.limits.cpu=0 \
            --set rayService.headGroupSpec.resources.limits.memory=2Gi \
            --set rayService.headGroupSpec.resources.requests.cpu=0 \
            --set rayService.headGroupSpec.resources.requests.memory=2Gi \
            --set rayService.workerGroupSpecs[0].replicas=1 \
            --set rayService.workerGroupSpecs[0].minReplicas=1 \
            --set rayService.workerGroupSpecs[0].maxReplicas=1 \
            --set rayService.workerGroupSpecs[0].groupName=test-group \
            --set rayService.workerGroupSpecs[0].gpuWorkerGroup.enabled=false \
            --set rayService.workerGroupSpecs[0].resources.limits.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.limits.memory=2Gi \
            --set rayService.workerGroupSpecs[0].resources.requests.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.requests.memory=2Gi \
            --set tags.observability=false

      - name: Wait for model deployment
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=controller-model,app.kubernetes.io/instance=model" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Run ${{ inputs.component }} integration test (latest)
        if: inputs.target == 'latest'
        run: |
          git clone https://github.com/instill-ai/${{ inputs.component }}.git
          cd ${{ inputs.component }}
          make integration-test API_GATEWAY_URL=localhost:${API_GATEWAY_PORT}

  helm-integration-test-latest-mac:
    if: false
    # if: inputs.target == 'latest' && github.ref == 'refs/heads/main'
    runs-on: [self-hosted, macOS, model]
    timeout-minutes: 30
    steps:
      - name: Set up environment
        run: |
          brew install make

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Check if Model Helm release exists
        id: check-model-helm-release
        run: |
          if helm ls -n instill-ai | grep -q 'model'; then
            echo "Helm release 'model' found."
            echo "release_exists=true" >> $GITHUB_OUTPUT
          else
            echo "Helm release 'model' not found."
          fi

      - name: Uninstall Model Helm Release
        if: steps.check-model-helm-release.outputs.release_exists == 'true'
        run: |
          helm uninstall model --namespace instill-ai

      - name: Install k6
        run: |
          brew install k6

      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          repository: instill-ai/core

      - name: Load .env file
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Check if Core Helm release exists
        id: check-core-helm-release
        run: |
          if helm ls -n instill-ai | grep -q 'core'; then
            echo "Helm release 'core' found."
            echo "release_exists=true" >> $GITHUB_OUTPUT
          else
            echo "Helm release 'core' not found."
          fi

      - name: Uninstall Core Helm Release
        if: steps.check-core-helm-release.outputs.release_exists == 'true'
        run: |
          helm uninstall core --namespace instill-ai
          kubectl delete namespace instill-ai

      - name: Launch Helm Instill Core (latest)
        run: |
          helm install core charts/core --namespace instill-ai --create-namespace \
            --set edition=k8s-ce:test \
            --set apiGateway.image.tag=latest \
            --set mgmtBackend.image.tag=latest \
            --set console.image.tag=latest \
            --set tags.observability=false

      - name: Wait for core pods up
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Port-forward of api-gateway
        run: |
          API_GATEWAY_POD_NAME=$(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o json | jq -r '.items[0].metadata.name')
          kubectl --namespace instill-ai port-forward ${API_GATEWAY_POD_NAME} ${API_GATEWAY_PORT}:${API_GATEWAY_PORT} > /dev/null 2>&1 &
          while ! nc -vz localhost ${API_GATEWAY_PORT} > /dev/null 2>&1; do sleep 1; done

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file (model)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Launch Helm Instill Model (latest)
        run: |
          helm install model charts/model --namespace instill-ai --create-namespace \
            --set itMode.enabled=true \
            --set edition=k8s-ce:test \
            --set modelBackend.image.tag=latest \
            --set controllerModel.image.tag=latest \
            --set rayService.image.tag=latest-arm \
            --set rayService.headGroupSpec.resources.limits.cpu=0 \
            --set rayService.headGroupSpec.resources.limits.memory=2Gi \
            --set rayService.headGroupSpec.resources.requests.cpu=0 \
            --set rayService.headGroupSpec.resources.requests.memory=2Gi \
            --set rayService.workerGroupSpecs[0].replicas=1 \
            --set rayService.workerGroupSpecs[0].minReplicas=1 \
            --set rayService.workerGroupSpecs[0].maxReplicas=1 \
            --set rayService.workerGroupSpecs[0].groupName=test-group \
            --set rayService.workerGroupSpecs[0].gpuWorkerGroup.enabled=false \
            --set rayService.workerGroupSpecs[0].resources.limits.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.limits.memory=2Gi \
            --set rayService.workerGroupSpecs[0].resources.requests.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.requests.memory=2Gi \
            --set tags.observability=false

      - name: Wait for model deployment
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=controller-model,app.kubernetes.io/instance=model" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Run ${{ inputs.component }} integration test (latest)
        if: inputs.target == 'latest'
        run: |
          git clone https://github.com/instill-ai/${{ inputs.component }}.git
          cd ${{ inputs.component }}
          make integration-test API_GATEWAY_URL=localhost:${API_GATEWAY_PORT}

      - name: Uninstall Core and Model Helm Release
        run: |
          helm uninstall model --namespace instill-ai
          helm uninstall core --namespace instill-ai
          kubectl delete namespace instill-ai

  helm-integration-test-release-linux:
    if: inputs.target == 'release'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      # mono occupies port 8084 which conflicts with mgmt-backend
      - name: Stop mono service
        run: |
          sudo kill -9 `sudo lsof -t -i:8084`
          sudo lsof -i -P -n | grep LISTEN

      - name: Pre Free Disk Space (Ubuntu)
        run: |
          df --human-readable
          sudo apt clean
          rm --recursive --force "$AGENT_TOOLSDIRECTORY"

      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: false
          docker-images: true
          swap-storage: true

      - name: Start Minikube
        run: minikube start --cpus 4 --memory 12G

      - name: Checkout repo (core)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/core

      - name: Load .env file (core)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Launch Helm Instill Core (release)
        run: |
          helm install core charts/core --namespace instill-ai --create-namespace \
            --set edition=k8s-ce:test \
            --set apiGateway.image.tag=${API_GATEWAY_VERSION} \
            --set mgmtBackend.image.tag=${MGMT_BACKEND_VERSION} \
            --set console.image.tag=${CONSOLE_VERSION} \
            --set tags.observability=false

      - name: Wait for core pods up
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Port-forward of api-gateway
        run: |
          API_GATEWAY_POD_NAME=$(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o json | jq -r '.items[0].metadata.name')
          kubectl --namespace instill-ai port-forward ${API_GATEWAY_POD_NAME} ${API_GATEWAY_PORT}:${API_GATEWAY_PORT} > /dev/null 2>&1 &
          while ! nc -vz localhost ${API_GATEWAY_PORT} > /dev/null 2>&1; do sleep 1; done

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file (model)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Install k6
        run: |
          curl https://github.com/grafana/k6/releases/download/v${{ env.K6_VERSION }}/k6-v${{ env.K6_VERSION }}-linux-amd64.tar.gz -L | tar xvz --strip-components 1 && sudo cp k6 /usr/bin

      - name: Uppercase component name
        id: uppercase
        run: |
          echo "COMPONENT_NAME=$(echo ${{ inputs.component }} | tr 'a-z-' 'A-Z_')" >> $GITHUB_OUTPUT

      - name: Launch Instill Model (release)
        run: |
          helm install model charts/model --namespace instill-ai --create-namespace \
            --set itMode.enabled=true \
            --set edition=k8s-ce:test \
            --set modelBackend.image.tag=${MODEL_BACKEND_VERSION} \
            --set controllerModel.image.tag=${CONTROLLER_MODEL_VERSION} \
            --set rayService.image.tag=${RAY_SERVER_VERSION}-cpu \
            --set rayService.headGroupSpec.resources.limits.cpu=0 \
            --set rayService.headGroupSpec.resources.limits.memory=2Gi \
            --set rayService.headGroupSpec.resources.requests.cpu=0 \
            --set rayService.headGroupSpec.resources.requests.memory=2Gi \
            --set rayService.workerGroupSpecs[0].replicas=1 \
            --set rayService.workerGroupSpecs[0].minReplicas=1 \
            --set rayService.workerGroupSpecs[0].maxReplicas=1 \
            --set rayService.workerGroupSpecs[0].groupName=test-group \
            --set rayService.workerGroupSpecs[0].gpuWorkerGroup.enabled=false \
            --set rayService.workerGroupSpecs[0].resources.limits.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.limits.memory=2Gi \
            --set rayService.workerGroupSpecs[0].resources.requests.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.requests.memory=2Gi \
            --set tags.observability=false

      - name: Wait for model deployment
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=controller-model,app.kubernetes.io/instance=model" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Run ${{ inputs.component }} integration test (release)
        env:
          COMPONENT_VERSION: ${{ env[format('{0}_VERSION', steps.uppercase.outputs.COMPONENT_NAME)] }}
        run: |
          git clone -b v$COMPONENT_VERSION https://github.com/instill-ai/${{ inputs.component }}.git
          cd ${{ inputs.component }}
          make integration-test API_GATEWAY_URL=localhost:${API_GATEWAY_PORT}

  helm-integration-test-release-mac:
    if: false
    # if: inputs.target == 'release'
    runs-on: [self-hosted, macOS, model]
    timeout-minutes: 30
    steps:
      - name: Set up environment
        run: |
          brew install make

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Check if Model Helm release exists
        id: check-model-helm-release
        run: |
          if helm ls -n instill-ai | grep -q 'model'; then
            echo "Helm release 'model' found."
            echo "release_exists=true" >> $GITHUB_OUTPUT
          else
            echo "Helm release 'model' not found."
          fi

      - name: Uninstall Model Helm Release
        if: steps.check-model-helm-release.outputs.release_exists == 'true'
        run: |
          helm uninstall model --namespace instill-ai

      - name: Install k6
        run: |
          brew install k6

      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          repository: instill-ai/core

      - name: Load .env file
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Check if Core Helm release exists
        id: check-core-helm-release
        run: |
          if helm ls -n instill-ai | grep -q 'core'; then
            echo "Helm release 'core' found."
            echo "release_exists=true" >> $GITHUB_OUTPUT
          else
            echo "Helm release 'core' not found."
          fi

      - name: Uninstall Core Helm Release
        if: steps.check-core-helm-release.outputs.release_exists == 'true'
        run: |
          helm uninstall core --namespace instill-ai
          kubectl delete namespace instill-ai

      - name: Launch Helm Instill Core (release)
        run: |
          helm install core charts/core --namespace instill-ai --create-namespace \
            --set edition=k8s-ce:test \
            --set apiGateway.image.tag=${API_GATEWAY_VERSION} \
            --set mgmtBackend.image.tag=${MGMT_BACKEND_VERSION} \
            --set console.image.tag=${CONSOLE_VERSION} \
            --set tags.observability=false

      - name: Wait for core pods up
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Port-forward of core-api-gateway
        run: |
          API_GATEWAY_POD_NAME=$(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=api-gateway,app.kubernetes.io/instance=core" -o json | jq -r '.items[0].metadata.name')
          kubectl --namespace instill-ai port-forward ${API_GATEWAY_POD_NAME} ${API_GATEWAY_PORT}:${API_GATEWAY_PORT} > /dev/null 2>&1 &
          while ! nc -vz localhost ${API_GATEWAY_PORT} > /dev/null 2>&1; do sleep 1; done

      - name: Checkout repo (model)
        uses: actions/checkout@v4
        with:
          repository: instill-ai/model

      - name: Load .env file (model)
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env

      - name: Uppercase component name
        id: uppercase
        run: |
          echo "COMPONENT_NAME=$(echo ${{ inputs.component }} | tr 'a-z-' 'A-Z_')" >> $GITHUB_OUTPUT

      - name: Launch Helm Instill Model (release)
        run: |
          helm install model charts/model --namespace instill-ai --create-namespace \
            --set itMode.enabled=true \
            --set edition=k8s-ce:test \
            --set modelBackend.image.tag=${MODEL_BACKEND_VERSION} \
            --set controllerModel.image.tag=${CONTROLLER_MODEL_VERSION} \
            --set rayService.image.tag=${RAY_SERVER_VERSION}-arm \
            --set rayService.headGroupSpec.resources.limits.cpu=0 \
            --set rayService.headGroupSpec.resources.limits.memory=2Gi \
            --set rayService.headGroupSpec.resources.requests.cpu=0 \
            --set rayService.headGroupSpec.resources.requests.memory=2Gi \
            --set rayService.workerGroupSpecs[0].replicas=1 \
            --set rayService.workerGroupSpecs[0].minReplicas=1 \
            --set rayService.workerGroupSpecs[0].maxReplicas=1 \
            --set rayService.workerGroupSpecs[0].groupName=test-group \
            --set rayService.workerGroupSpecs[0].gpuWorkerGroup.enabled=false \
            --set rayService.workerGroupSpecs[0].resources.limits.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.limits.memory=2Gi \
            --set rayService.workerGroupSpecs[0].resources.requests.cpu=2 \
            --set rayService.workerGroupSpecs[0].resources.requests.memory=2Gi \
            --set tags.observability=false

      - name: Wait for model deployment
        run: |
          while [[ $(kubectl get pods --namespace instill-ai -l "app.kubernetes.io/component=controller-model,app.kubernetes.io/instance=model" -o 'jsonpath={..status.phase}') != *"Running"* ]]; do
            echo "$(kubectl get pods --namespace instill-ai)"
            sleep 10
          done

      - name: Run ${{ inputs.component }} integration test (release)
        env:
          COMPONENT_VERSION: ${{ env[format('{0}_VERSION', steps.uppercase.outputs.COMPONENT_NAME)] }}
        run: |
          git clone -b v$COMPONENT_VERSION https://github.com/instill-ai/${{ inputs.component }}.git
          cd ${{ inputs.component }}
          make integration-test API_GATEWAY_URL=localhost:${API_GATEWAY_PORT}

      - name: Uninstall Core and Model Helm Release
        run: |
          helm uninstall model --namespace instill-ai
          helm uninstall core --namespace instill-ai
          kubectl delete namespace instill-ai
