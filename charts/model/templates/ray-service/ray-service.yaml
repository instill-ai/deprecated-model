{{- $rayConda := .Values.persistence.persistentVolumeClaim.rayConda -}}
apiVersion: ray.io/v1
# kind: RayService
kind: RayCluster
metadata:
  name: {{ template "model.ray-service" . }}
  # annotations:
  #   ray.io/ft-enabled: "true"
spec:
  # serviceUnhealthySecondThreshold: 900 # Config for the health check threshold for Ray Serve applications. Default value is 900.
  # deploymentUnhealthySecondThreshold: 300 # Config for the health check threshold for Ray dashboard agent. Default value is 300.
  # serveConfigV2: |
  #   applications: []
  #   grpc_options:
  #       port: 9000
  #       grpc_servicer_functions:
  #           - ray_pb2_grpc.add_RayServiceServicer_to_server
  # rayClusterConfig:
  rayVersion: {{ .Values.rayService.image.version }} # should match the Ray version in the image of the containers
  ## raycluster autoscaling config
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    resources:
      limits:
        cpu: "1"
        memory: "1000Mi"
      requests:
        cpu: "1"
        memory: "1000Mi"
  ######################headGroupSpecs#################################
  headGroupSpec:
    # The `rayStartParams` are used to configure the `ray start` command.
    # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
    # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
    rayStartParams:
      num-cpus: "0"
      disable-usage-stats: "true"
    #pod template
    template:
      spec:
        # env:
            #   - name: RAY_REDIS_ADDRESS
            #     value: {{ template "core.redis.addr" . }}
        containers:
          - name: ray-head
            image: {{ .Values.rayService.image.repository }}:{{ .Values.rayService.image.tag }}
            resources:
              limits:
                cpu: "0"
                memory: 2Gi
              requests:
                cpu: "0"
                memory: 2Gi
            ports:
              - containerPort: 6379
                name: gcs-server
              - containerPort: 8265 # Ray dashboard
                name: dashboard
              - containerPort: 10001
                name: client
              - containerPort: 8000
                name: serve
              - containerPort: 9000
                name: serve-grpc
  workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 1
      minReplicas: 1
      maxReplicas: 5
      # logical group name, for this called small-group, also can be functional
      groupName: cpu-group
      # The `rayStartParams` are used to configure the `ray start` command.
      # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
      # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
      rayStartParams:
          disable-usage-stats: "true"
      #pod template
      template:
        spec:
          volumes:
            - name: ray-conda
            {{- if not .Values.persistence.enabled }}
              emptyDir: {}
            {{- else if $rayConda.existingClaim }}
              persistentVolumeClaim:
                claimName: {{ $rayConda.existingClaim }}
            {{- else }}
              persistentVolumeClaim:
                claimName: ray-conda-data-volume
            {{- end }}
            - name: cp-conda-env-configmap
              configMap:
                name: cp-conda-env
                defaultMode: 0777
                items:
                  - key: cp_conda_env_and_start_ray_serve.sh
                    path: cp_conda_env_and_start_ray_serve.sh
          containers:
            - name: ray-worker
              image: {{ .Values.rayService.image.repository }}:{{ .Values.rayService.image.tag }}
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh","-c","ray stop"]
                postStart:
                  exec:
                    command: ["/bin/sh","-c","/home/ray/script/cp_conda_env_and_start_ray_serve.sh"]
              resources:
                limits:
                  cpu: "2"
                  memory: "2Gi"
                requests:
                  cpu: "2"
                  memory: "2Gi"
              volumeMounts:
                - mountPath: /ray-conda-pack
                  name: ray-conda
                - mountPath: /home/ray/script
                  name: cp-conda-env-configmap
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cp-conda-env
data:
  cp_conda_env_and_start_ray_serve.sh: |
    #!/bin/bash

    # wait for ray cluster to finish initialization
    while true; do
        ray health-check 2>/dev/null
        if [ "$?" = "0" ]; then
            break
        else
            echo "INFO: waiting for ray head to start"
            sleep 1
        fi
    done

    cp -r /home/ray/anaconda3/* /ray-conda-pack

    echo "INFO: Conda env copying done"

    serve start --http-host=0.0.0.0 --grpc-port 9000 --grpc-servicer-functions ray_pb2_grpc.add_RayServiceServicer_to_server

    echo "INFO: Start ray serve"
